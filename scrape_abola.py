from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
import time

# Configura√ß√£o do Selenium para Chrome
options = Options()
options.add_argument("--headless")  # Roda o navegador sem abrir janela
options.add_argument("--disable-gpu")
options.add_argument("--no-sandbox")
options.add_argument("--log-level=3")  # Reduz mensagens no terminal

# Inicializar o navegador
service = Service(ChromeDriverManager().install())
driver = webdriver.Chrome(service=service, options=options)

# Acessar o site
url = "https://www.abola.pt/"
driver.get(url)

# Esperar at√© que o carrossel carregue
try:
    WebDriverWait(driver, 10).until(
        EC.presence_of_element_located((By.CLASS_NAME, "abola-slider"))
    )
    print("üîÑ P√°gina carregada com sucesso!")
except:
    print("‚ö†Ô∏è O carrossel demorou muito a carregar!")

# Recolher links das 10 primeiras not√≠cias
links_noticias = []
for i in range(10):  # Pegamos as 10 primeiras not√≠cias do carrossel
    try:
        WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.CLASS_NAME, "splide__slide"))
        )
        noticias = driver.find_elements(By.CLASS_NAME, "splide__slide")
        noticia = noticias[i]

        link_element = noticia.find_element(By.TAG_NAME, "a")
        link = link_element.get_attribute("href")
        if link.startswith("/"):
            link = f"https://www.abola.pt{link}"

        links_noticias.append(link)
    except Exception as e:
        print(f"‚ö†Ô∏è Erro ao recolher link da not√≠cia {i+1}: {e}")
        continue

# Lista para armazenar os dados das not√≠cias
dados = []

for i, link in enumerate(links_noticias, start=1):
    try:
        # Acessar a p√°gina da not√≠cia
        driver.get(link)
        time.sleep(5)  # Espera extra para carregar o conte√∫do da not√≠cia

        # Capturar o t√≠tulo correto dentro da p√°gina da not√≠cia
        try:
            titulo_element = WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.CLASS_NAME, "titulo"))
            )
            titulo = titulo_element.text.strip()
        except:
            titulo = "‚ùå T√≠tulo n√£o encontrado"

        # Capturar o conte√∫do da not√≠cia
        try:
            conteudo_element = WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.CLASS_NAME, "single-news-content"))
            )
            paragrafos = conteudo_element.find_elements(By.TAG_NAME, "p")  # Capturar todos os par√°grafos
            conteudo = "\n".join([p.text.strip() for p in paragrafos if p.text.strip()])  # Juntar os par√°grafos
        except:
            conteudo = "‚ùå N√£o foi poss√≠vel recolher a not√≠cia."

        # Adicionar os dados na lista
        dados.append({
            "T√≠tulo": titulo,
            "Link": link,
            "Not√≠cia": conteudo
        })

        # Voltar √† p√°gina principal para carregar novamente a lista
        driver.get(url)
        time.sleep(3)  # Pequena espera para garantir que tudo recarregue antes da pr√≥xima not√≠cia

    except Exception as e:
        print(f"‚ö†Ô∏è Erro ao processar not√≠cia {i}: {e}")
        continue

# Fechar navegador
driver.quit()

# Imprimir os dados recolhidos no terminal
if not dados:
    print("‚ùå Nenhuma not√≠cia foi extra√≠da. Verifique os seletores CSS ou se o site bloqueou a raspagem.")
else:
    print("\nüì¢ Not√≠cias Recolhidas:\n")
    for i, noticia in enumerate(dados, start=1):
        print(f"{i}. {noticia['T√≠tulo']}")
        print(f"   üìé Link: {noticia['Link']}")
        print(f"   üì∞ Not√≠cia:\n{noticia['Not√≠cia'][:500]}...")  # Exibir apenas os primeiros 500 caracteres
        print("-" * 100)
